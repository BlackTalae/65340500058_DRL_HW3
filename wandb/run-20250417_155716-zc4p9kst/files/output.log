device:  cuda
===== Training Config 1/1: {'num_of_action': 7, 'action_range': 20.0, 'learning_rate': 0.001, 'epsilon_decay': 0.0003, 'discount': 0.01} =====
  0%|                                                                                                                                                                              | 0/5000 [00:00<?, ?it/s]
Error executing job with overrides: []
Traceback (most recent call last):
  File "/home/talae/IsaacLab/source/isaaclab_tasks/isaaclab_tasks/utils/hydra.py", line 101, in hydra_main
    func(env_cfg, agent_cfg, *args, **kwargs)
  File "/home/talae/DRL_HW3/DRL_HW3/scripts/Function_based/train_linearQ.py", line 172, in main
    step, reward = agent.learn(env, 1000)
  File "/home/talae/DRL_HW3/DRL_HW3/RL_Algorithm/Function_based/Linear_Q.py", line 159, in learn
    self.update(obs_list, action, reward, next_obs_list, done)
  File "/home/talae/DRL_HW3/DRL_HW3/RL_Algorithm/Function_based/Linear_Q.py", line 84, in update
    current_q = self.q(phi_s, a=action)
  File "/home/talae/DRL_HW3/DRL_HW3/RL_Algorithm/Function_based/Linear_Q.py", line 120, in q
    q_values = torch.dot(obs, self.w)
RuntimeError: 1D tensors expected, but got 2D and 2D tensors
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.